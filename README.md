# Artificial Neural Networks (UE22EC343AC1)

**Institution:** P.E.S. University

**Department:** Department of Electronics and Communication Engineering

**Semester:** B. Tech 5th Semester

**Session:** Aug-Dec 2024

**Faculty:**
- **RR Campus:** Prof. Swetha R (RS)

**Teaching Assistant and Content Curator for Course:**
- **Pramath G H - pramath.haritz@gmail.com**

## Course Overview

The "Artificial Neural Networks" course (UE22EC343AC1) offers a comprehensive introduction to the concepts, models, and applications of neural networks. The course is designed to provide students with both theoretical knowledge and practical experience in implementing neural networks using Python and MATLAB.

## Learning Objectives

By the end of this course, students will be able to:
1. Understand the fundamental concepts of neural networks and their biological inspiration.
2. Explore different neural network architectures and learning algorithms.
3. Implement neural network models for various applications using Python and MATLAB.
4. Analyze the performance of neural networks and optimize their parameters.
5. Develop innovative solutions for real-world problems using neural network models.

## Course Structure

The course is divided into four main units, each covering specific aspects of neural networks(refer to the specific sections in the textbook):

### Unit 1: Basics of Neural Networks
Part 1: 
- 1.1 What is a Neural Network?
- 1.2 Human Brain
- 1.3 Models of a Neuron 
- 1.4 Neural Networks viewed as Directed Graphs
- 1.5 Feedback
- 1.6 Network Architectures
- 1.7 Knowledge Representation
- 2.1 Introduction to Learning
- 2.2 Error-Correction Learning
- 2.3 Memory-Based Learning
- 2.4 Hebbian Learning
- 2.5 Competitive Learning
- 2.6 Boltzmann Learning
- 2.7 Credit-Assignment Problem
- 2.8 Learning with a Teacher
- 2.9 Learning without a Teacher

Part 2:
- 3.1 Introduction
- 3.2 Adaptive Filtering Problem
- 3.3 Uncontrained Optimization Problem
    - Method of Steepest Decent
    - Newton's Method
    - Gauss-Newton Method 
- 3.4 Linear Least-Squares Filters
    - Winer Filter 
- 3.5 Least-Mean-Square Algorithm
- 3.6 Learning Curves
- 3.7 Learning Rate Annealing Techniques

### Unit 2: Single and Multi-layer Perceptron
- 3.8 Perceptron
- 3.9 Perceptron Convergence Theorem
- 4.1 Introduction to Multilayer Perceptron
- 4.2 Preliminaries
- 4.3 Back-Propagation Algorithm
- 4.5 XOR Problem
- 4.6 Heuristics for Making the BPA Perform Better
- 4.11 Hessian Matrix
- 4.12 Genralization
- 4.13 Approximations of Functions
- 4.14 Cross Validation
- 4.15 Network Pruning Techniques
- 4.16 Virtues and Limitations of Back Propagation Learning


### Unit 3: Radial Basis Function Networks
- 5.1 Introduction
- 5.2 Coverâ€™s theorem on the separability of patterns
- 5.3 Interpolation Problem
- 5.4 Supervised learning as an ill-posed Hyper-surface reconstruction problem
- 5.5 Regularization Theory
- 5.6 Regularization Networks
- 5.7 Generalized RBF Networks
- 5.8 XOR Problem(Revisited)
- 5.11 Comparision of RBF Networks and Multilayer Perceptron

### Unit 4: Unsupervised Learning Algorithms
- 8.1 Introduction to PCA
- 8.2 Some Intuitive Principles of Self-Organization
- 8.3 PCA
- 8.4 Hebbian-Based maximum eigen filter
- 8.5 Hebbian-Based PCA
- 9.1 Introduction to SOM
- 9.2 Two Basic Feature-Mapping Models
- 9.3 SOM
- 9.5 Properties of Feature Map
- 9.9 Hierarchical Vector Quantization


## Implementations

### Unit 1: Basics of Neural Networks
- Various Activation Functions
- Adaline (Adaptive Linear Neural)

### Unit 2: Single and Multi-layer Perceptron
- BPA Algorithm
- Single Layer Feed Forward Network
- Multi-Layer Feed Forward Network

### Unit 3: Radial Basis Function Networks
- RBF Neural Network

### Unit 4: Unsupervised Learning Algorithms
- PCA
- SOM

### Extra:
- Applications of Neural Networks:
    - Forcasting
    - Image Processing 
    - Compression



## Assessment

The assessment for this course is based on both formative and summative evaluations, including:
- **ISA Tests:** 2 Computer-Based Test (CBT) mode (30 Marks)
- **Assignments and Hands-On Exercises:** (10 Marks)
- **Term Project:** (10 Marks, including presentation)
- **End Semester Assessment (ESA):** Hybrid mode, reduced to 50 Marks as per university policy

## Textbooks and References

**Textbook:**
- "Neural Networks: A Comprehensive Foundation," S. Haykin, 2nd Edition, Prentice Hall of India, 2003.

**Reference Books:**
- Additional references will be provided during the course.
